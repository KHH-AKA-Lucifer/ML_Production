{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe kernel failed to start as 'TypeAliasType' could not be imported from 'c:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\typing_extensions.py'.\n",
      "\u001b[1;31mClick <a href='https://aka.ms/kernelFailuresModuleImportErrFromFile'>here</a> for more info."
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import cv2\n",
    "import os\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "root_path = os.getcwd()\n",
    "train_path = root_path+\"/cats_and_dogs_filtered/train\"\n",
    "val_path = root_path+\"/cats_and_dogs_filtered/validation\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_size = (64,64)\n",
    "input_shape = (64,64,3)\n",
    "\n",
    "def load_img(img_path):\n",
    "    img = cv2.imread(img_path)\n",
    "    img = cv2.resize(img,input_size)\n",
    "    return img\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "X_train,Y_train = [],[]\n",
    "X_val,Y_val = [],[]\n",
    "\n",
    "\n",
    "# Load Train\n",
    "for cur_class in os.listdir(train_path):\n",
    "    label = \"\"\n",
    "    if cur_class == \"cats\":\n",
    "        label = [1,0]\n",
    "    else:\n",
    "        label = [0,1]\n",
    "\n",
    "    for filename in os.listdir(train_path+\"/\"+cur_class):\n",
    "        img_path = train_path+\"/\"+cur_class+\"/\"+filename\n",
    "        img = load_img(img_path)\n",
    "        X_train.append(img)\n",
    "        Y_train.append(label)\n",
    "\n",
    "\n",
    "\n",
    "# Load Test\n",
    "for cur_class in os.listdir(val_path):\n",
    "    label = \"\"\n",
    "    if cur_class == \"cats\":\n",
    "        label = [1,0]\n",
    "    else:\n",
    "        label = [0,1]\n",
    "\n",
    "    for filename in os.listdir(val_path+\"/\"+cur_class):\n",
    "        img_path = val_path+\"/\"+cur_class+\"/\"+filename\n",
    "        img = load_img(img_path)\n",
    "        X_val.append(img)\n",
    "        Y_val.append(label)\n",
    "\n",
    "\n",
    "X_train = np.array(X_train)\n",
    "Y_train = np.array(Y_train)\n",
    "X_val = np.array(X_val)\n",
    "Y_val = np.array(Y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.pyplot import figure\n",
    "\n",
    "index = 19\n",
    "\n",
    "figure(figsize=(8, 6), dpi=80)\n",
    "plt.subplot(1,2,1)\n",
    "plt.title(\"Train Dog\")\n",
    "plt.imshow(X_train[index])\n",
    "\n",
    "\n",
    "plt.subplot(1,2,2)\n",
    "plt.title(\"Val Dog\")\n",
    "plt.imshow(X_val[index])\n",
    "\n",
    "\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D,Dense,Flatten,MaxPooling2D,Dropout\n",
    "\n",
    "\n",
    "model = Sequential([\n",
    "    Conv2D(32, (3, 3), activation='relu', input_shape=(64, 64, 3)),  # Conv Layer 1\n",
    "    MaxPooling2D((2, 2)),                                           # Max Pooling Layer 1\n",
    "    Conv2D(64, (3, 3), activation='relu'),                          # Conv Layer 2\n",
    "    MaxPooling2D((2, 2)),                                           # Max Pooling Layer 2\n",
    "    Flatten(),                                                      # Flatten Layer\n",
    "    Dense(128, activation='relu'),                                  # Fully Connected Layer\n",
    "    Dense(2, activation='softmax')      \n",
    "])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Conv Layer 1:\n",
    "- Input Shape: (64, 64, 3)\n",
    "- Number of Filters: 32\n",
    "- Kernel Size: (3, 3)\n",
    "- Parameters: (3 * 3 * 3 + 1) * 32 = 896\n",
    "\n",
    "\n",
    "#### 3. Conv Layer 2:\n",
    "- Input Shape: (31, 31, 32) (The size is halved after max pooling)\n",
    "- Number of Filters: 64\n",
    "- Kernel Size: (3, 3)\n",
    "- Parameters: (3 * 3 * 32 + 1) * 64 = 18,496\n",
    "\n",
    "\n",
    "\n",
    "#### 5. Flatten Layer:\n",
    "- The output from the second conv layer and max pooling is reshaped into a flat vector.\n",
    "- Shape after second pooling: (14, 14, 64)\n",
    "- Total Units after Flatten: 14 * 14 * 64 = 12,544\n",
    "- No trainable parameters here, as this layer just reshapes the data.\n",
    "\n",
    "#### 6. Fully Connected (Dense) Layer:\n",
    "- Input Size: 12,544\n",
    "- Output Neurons: 128\n",
    "- Parameters: (12,544 + 1) * 128 = 1,605,760\n",
    "\n",
    "#### 7. Output Layer:\n",
    "- Input Size: 128\n",
    "- Output Neurons: 2 (for binary classification)\n",
    "- Parameters: (128 + 1) * 2 = 258\n",
    "\n",
    "\n",
    "\n",
    "- Conv Layer 1: 896\n",
    "- Conv Layer 2: 18,496\n",
    "- Dense Layer: 1,605,760\n",
    "- Output Layer: 258\n",
    "- Total Trainable Parameters = 896 + 18,496 + 1,605,760 + 258 = 1,625,410"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "tensorflow.keras.utils.plot_model(model, show_shapes=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=Adam(0.001),\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(\n",
    "    x = np.array(X_train),\n",
    "    y = np.array(Y_train),\n",
    "    validation_data = (X_val,Y_val),\n",
    "    batch_size=16,\n",
    "    epochs=10,\n",
    "    verbose=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "acc = history.history['accuracy']\n",
    "val_acc = history.history['val_accuracy']\n",
    "\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "\n",
    "plt.figure(figsize=(8, 8))\n",
    "plt.subplot(2, 1, 1)\n",
    "plt.plot(acc, label='Training Accuracy')\n",
    "plt.plot(val_acc, label='Validation Accuracy')\n",
    "plt.legend(loc='lower right')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.title('Training and Validation Accuracy')\n",
    "\n",
    "plt.subplot(2, 1, 2)\n",
    "plt.plot(loss, label='Training Loss')\n",
    "plt.plot(val_loss, label='Validation Loss')\n",
    "plt.legend(loc='upper right')\n",
    "plt.ylabel('Cross Entropy')\n",
    "\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = [\"cat\",\"dog\"]\n",
    "\n",
    "test_img_path = \"./cats_and_dogs_filtered/validation/cats/cat.2000.jpg\"\n",
    "\n",
    "\n",
    "\n",
    "test_img = np.array([load_img(test_img_path)])\n",
    "print(test_img.shape)\n",
    "\n",
    "pred_ = model.predict(test_img)\n",
    "pred_label = labels[np.argmax(pred_)]\n",
    "print(pred_label)\n",
    "plt.imshow(test_img[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_loss, eval_acc = model.evaluate(X_val,Y_val)\n",
    "print('Eval loss: {}, Eval accuracy: {}'.format(eval_loss, eval_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#HDF 5 save format \n",
    "model_file = \"sample_model.h5\"\n",
    "model.save(model_file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_model = tf.keras.models.load_model(model_file)\n",
    "eval_loss, eval_acc = model.evaluate(X_val,Y_val)\n",
    "print('Eval loss: {}, Eval accuracy: {}'.format(eval_loss, eval_acc))\n",
    "new_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ths",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
